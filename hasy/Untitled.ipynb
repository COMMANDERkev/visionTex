{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M:\\Kevin\\code\\python\\visionTex\\input\\HASYv2\n"
     ]
    }
   ],
   "source": [
    "hasyv2_path = \"../input/HASYv2\"\n",
    "hasyv2_path = os.path.abspath(hasyv2_path)\n",
    "print(hasyv2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['classification-task', 'hasy-data', 'hasy-data-labels.csv', 'hasy_tools.py', 'README.txt', 'symbols.csv', 'verification-task', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(hasyv2_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hasy-data-labels': 'M:\\\\Kevin\\\\code\\\\python\\\\visionTex\\\\input\\\\HASYv2\\\\hasy-data-labels.csv', 'symbols': 'M:\\\\Kevin\\\\code\\\\python\\\\visionTex\\\\input\\\\HASYv2\\\\symbols.csv'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_files = {}\n",
    "for f in os.listdir(hasyv2_path):\n",
    "    if f.endswith(\".csv\"):\n",
    "        csv_files[f.split(\".\")[0]] = os.path.join(hasyv2_path, f)\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(csv_files['hasy-data-labels'])\n",
    "symbols = pd.read_csv(csv_files['symbols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     path  symbol_id latex  user_id\n",
      "0  hasy-data/v2-00000.png         31     A       50\n",
      "1  hasy-data/v2-00001.png         31     A       10\n",
      "2  hasy-data/v2-00002.png         31     A       43\n",
      "3  hasy-data/v2-00003.png         31     A       43\n",
      "4  hasy-data/v2-00004.png         31     A     4435 \n",
      "\n",
      " RangeIndex(start=0, stop=168233, step=1) \n",
      "\n",
      " Index(['path', 'symbol_id', 'latex', 'user_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(labels.head(), \"\\n\\n\", labels.index, \"\\n\\n\", labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   symbol_id latex  training_samples  test_samples\n",
      "0         31     A               137            22\n",
      "1         32     B                53             8\n",
      "2         33     C               120            14\n",
      "3         34     D                50             8\n",
      "4         35     E                48             6 \n",
      "\n",
      " RangeIndex(start=0, stop=369, step=1) \n",
      "\n",
      " Index(['symbol_id', 'latex', 'training_samples', 'test_samples'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(symbols.head(), \"\\n\\n\", symbols.index, \"\\n\\n\", symbols.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOALS\n",
    "* Create simple network using pytorch to classify one fold\n",
    "    1. Load in data\n",
    "    2. Build network structure\n",
    "    3. Train model on specified data\n",
    "    4. Test and report: **min, max, average**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# might need this later\n",
    "def make_abspath(df, col_name):\n",
    "    ndf = pd.DataFrame(data=df)\n",
    "    col = ndf[col_name]\n",
    "    abspaths = []\n",
    "    for idx, p in col.iteritems():\n",
    "        if len(p.rsplit('/',maxsplit=1)) == 1:\n",
    "            path = p.rsplit('\\\\\\\\',maxsplit=1)[len(p.rsplit('\\\\\\\\',maxsplit=1)) - 1]\n",
    "        else:\n",
    "            path = p.rsplit('/',maxsplit=1)[len(p.rsplit('/',maxsplit=1)) - 1]\n",
    "        abspaths.append(os.path.join(data_path, path))\n",
    "    ndf['abspaths'] = pd.Series(abspaths, train1csv.index)\n",
    "    return ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train1csv.head(), '\\n\\n')\n",
    "# train1df = make_abspath(train1csv, 'path')\n",
    "# print(train1df, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. put HASY image data in this format\n",
    "    ```\n",
    "    main_directory/\n",
    "        ...class_a/\n",
    "        ......a_image_1.jpg\n",
    "        ......a_image_2.jpg\n",
    "        ...class_b/\n",
    "        ......b_image_1.jpg\n",
    "        ......b_image_2.jpg\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
